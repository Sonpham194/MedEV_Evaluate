{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ede573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a921aba29b4aa5a02b496d41ae9345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c196a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi: Hôm nay tôi giúp gì được cho anh đây, anh bạn?\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"VietAI/envit5-translation\"  # or one of the other names above\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "text = \"How can I help you today, my friend?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "translated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(translated)  # Should print Vietnamese translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec980fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "                                              0.0/84.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 84.1/84.1 kB ? eta 0:00:00\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "                                              0.0/104.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 104.1/104.1 kB 6.3 MB/s eta 0:00:00\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "                                              0.0/503.6 kB ? eta -:--:--\n",
      "     --------------------------------       430.1/503.6 kB 8.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- 503.6/503.6 kB 10.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from evaluate) (2.3.3)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "                                              0.0/119.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 119.7/119.7 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting pandas (from evaluate)\n",
      "  Downloading pandas-2.3.3-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "                                              0.0/11.3 MB ? eta -:--:--\n",
      "     -                                        0.5/11.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ---                                      0.9/11.3 MB 11.0 MB/s eta 0:00:01\n",
      "     ----                                     1.4/11.3 MB 12.8 MB/s eta 0:00:01\n",
      "     -----                                    1.6/11.3 MB 11.1 MB/s eta 0:00:01\n",
      "     ------                                   2.0/11.3 MB 9.7 MB/s eta 0:00:01\n",
      "     --------                                 2.3/11.3 MB 8.7 MB/s eta 0:00:02\n",
      "     ----------                               2.9/11.3 MB 9.1 MB/s eta 0:00:01\n",
      "     -----------                              3.3/11.3 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------                            3.8/11.3 MB 9.4 MB/s eta 0:00:01\n",
      "     ---------------                          4.4/11.3 MB 9.7 MB/s eta 0:00:01\n",
      "     -----------------                        5.0/11.3 MB 9.9 MB/s eta 0:00:01\n",
      "     -------------------                      5.5/11.3 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------                    6.1/11.3 MB 10.0 MB/s eta 0:00:01\n",
      "     ----------------------                   6.5/11.3 MB 10.1 MB/s eta 0:00:01\n",
      "     ------------------------                 7.0/11.3 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------------               7.6/11.3 MB 10.1 MB/s eta 0:00:01\n",
      "     ----------------------------             8.0/11.3 MB 10.3 MB/s eta 0:00:01\n",
      "     ------------------------------           8.7/11.3 MB 10.3 MB/s eta 0:00:01\n",
      "     --------------------------------         9.2/11.3 MB 10.4 MB/s eta 0:00:01\n",
      "     ----------------------------------       9.8/11.3 MB 10.3 MB/s eta 0:00:01\n",
      "     -----------------------------------     10.2/11.3 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------    10.7/11.3 MB 10.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  11.2/11.3 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  11.3/11.3 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 11.3/11.3 MB 9.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl (144 kB)\n",
      "                                              0.0/144.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 144.5/144.5 kB 8.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from evaluate) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from evaluate) (0.35.3)\n",
      "Requirement already satisfied: packaging in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from evaluate) (25.0)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: regex in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from sacrebleu) (2025.9.18)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-6.0.2-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "                                              0.0/4.0 MB ? eta -:--:--\n",
      "     ----                                     0.5/4.0 MB 14.2 MB/s eta 0:00:01\n",
      "     --------                                 0.9/4.0 MB 11.2 MB/s eta 0:00:01\n",
      "     ---------------                          1.5/4.0 MB 10.9 MB/s eta 0:00:01\n",
      "     ---------------------                    2.1/4.0 MB 11.2 MB/s eta 0:00:01\n",
      "     --------------------------               2.7/4.0 MB 11.4 MB/s eta 0:00:01\n",
      "     ------------------------------           3.1/4.0 MB 11.7 MB/s eta 0:00:01\n",
      "     -------------------------------------    3.8/4.0 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.0/4.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.0/4.0 MB 10.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "                                              0.0/26.2 MB ? eta -:--:--\n",
      "                                              0.4/26.2 MB 13.9 MB/s eta 0:00:02\n",
      "     -                                        1.1/26.2 MB 11.9 MB/s eta 0:00:03\n",
      "     --                                       1.7/26.2 MB 13.5 MB/s eta 0:00:02\n",
      "     ---                                      2.3/26.2 MB 11.9 MB/s eta 0:00:03\n",
      "     ----                                     2.8/26.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----                                     3.2/26.2 MB 11.2 MB/s eta 0:00:03\n",
      "     -----                                    3.5/26.2 MB 11.2 MB/s eta 0:00:03\n",
      "     ------                                   4.1/26.2 MB 10.9 MB/s eta 0:00:03\n",
      "     -------                                  4.7/26.2 MB 11.0 MB/s eta 0:00:02\n",
      "     --------                                 5.3/26.2 MB 10.9 MB/s eta 0:00:02\n",
      "     --------                                 5.8/26.2 MB 11.0 MB/s eta 0:00:02\n",
      "     ---------                                6.3/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     ----------                               6.7/26.2 MB 11.0 MB/s eta 0:00:02\n",
      "     ----------                               7.2/26.2 MB 11.2 MB/s eta 0:00:02\n",
      "     -----------                              7.7/26.2 MB 11.2 MB/s eta 0:00:02\n",
      "     ------------                             8.3/26.2 MB 11.2 MB/s eta 0:00:02\n",
      "     -------------                            8.8/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     --------------                           9.4/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     ---------------                          9.9/26.2 MB 11.3 MB/s eta 0:00:02\n",
      "     ---------------                         10.5/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     ----------------                        11.1/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     -----------------                       11.6/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     -----------------                       12.0/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------------                      12.6/26.2 MB 10.9 MB/s eta 0:00:02\n",
      "     -------------------                     13.1/26.2 MB 11.1 MB/s eta 0:00:02\n",
      "     -------------------                     13.3/26.2 MB 10.9 MB/s eta 0:00:02\n",
      "     -------------------                     13.4/26.2 MB 10.2 MB/s eta 0:00:02\n",
      "     --------------------                    13.9/26.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ---------------------                   14.2/26.2 MB 10.1 MB/s eta 0:00:02\n",
      "     ---------------------                    14.4/26.2 MB 9.9 MB/s eta 0:00:02\n",
      "     ----------------------                   14.8/26.2 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------                  15.1/26.2 MB 9.8 MB/s eta 0:00:02\n",
      "     -----------------------                  15.4/26.2 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------                  15.7/26.2 MB 9.4 MB/s eta 0:00:02\n",
      "     ------------------------                 15.9/26.2 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------------                 16.0/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "     ------------------------                 16.4/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "     -------------------------                16.6/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------------------                17.0/26.2 MB 8.3 MB/s eta 0:00:02\n",
      "     --------------------------               17.4/26.2 MB 8.3 MB/s eta 0:00:02\n",
      "     --------------------------               17.7/26.2 MB 8.1 MB/s eta 0:00:02\n",
      "     ---------------------------              18.2/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "     ----------------------------             18.6/26.2 MB 8.0 MB/s eta 0:00:01\n",
      "     -----------------------------            19.1/26.2 MB 7.9 MB/s eta 0:00:01\n",
      "     -----------------------------            19.6/26.2 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------------           20.1/26.2 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------          20.4/26.2 MB 7.7 MB/s eta 0:00:01\n",
      "     -------------------------------          20.7/26.2 MB 7.5 MB/s eta 0:00:01\n",
      "     --------------------------------         21.0/26.2 MB 7.4 MB/s eta 0:00:01\n",
      "     --------------------------------         21.6/26.2 MB 7.5 MB/s eta 0:00:01\n",
      "     ---------------------------------        22.0/26.2 MB 7.4 MB/s eta 0:00:01\n",
      "     ----------------------------------       22.5/26.2 MB 7.4 MB/s eta 0:00:01\n",
      "     -----------------------------------      23.1/26.2 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------------------------------     23.7/26.2 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------------    24.3/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "     -------------------------------------    24.8/26.2 MB 8.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   25.4/26.2 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  25.9/26.2 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  26.2/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  26.2/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 26.2/26.2 MB 8.3 MB/s eta 0:00:00\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "                                              0.0/143.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 143.5/143.5 kB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl (453 kB)\n",
      "                                              0.0/453.3 kB ? eta -:--:--\n",
      "     ------------------                     225.3/453.3 kB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 453.3/453.3 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->evaluate)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "                                              0.0/509.2 kB ? eta -:--:--\n",
      "     --------------------                   276.5/509.2 kB 8.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 509.2/509.2 kB 8.0 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7 (from pandas->evaluate)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "                                              0.0/347.8 kB ? eta -:--:--\n",
      "     -------------------------              235.5/347.8 kB 7.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 347.8/347.8 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pywin32>=226 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from portalocker->sacrebleu) (311)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "                                              0.0/44.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.0/44.0 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl (46 kB)\n",
      "                                              0.0/46.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "                                              0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB ? eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "                                              0.0/86.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 86.7/86.7 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in d:\\study\\jaist\\minor_project\\proj1\\medev_evaluate\\scripts\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tabulate, pyarrow, propcache, portalocker, multidict, lxml, frozenlist, dill, aiohappyeyeballs, yarl, sacrebleu, pandas, multiprocess, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 datasets-4.1.1 dill-0.4.0 evaluate-0.4.6 frozenlist-1.7.0 lxml-6.0.2 multidict-6.6.4 multiprocess-0.70.16 pandas-2.3.3 portalocker-3.2.0 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 sacrebleu-2.5.1 tabulate-0.9.0 tzdata-2025.2 xxhash-3.6.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949ba008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8399bee2b64d6294cbd2ea3877c43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 26.647313141084275, 'counts': [5, 3, 1, 0], 'totals': [7, 6, 5, 4], 'precisions': [71.42857142857143, 50.0, 20.0, 12.5], 'bp': 0.8668778997501817, 'sys_len': 7, 'ref_len': 8}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the BLEU metric\n",
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "# Suppose you have:\n",
    "predictions = [\"Xin chào, bạn khỏe không?\"]\n",
    "references = [[\"Chào bạn, bạn có khỏe không?\"]]  # List of lists\n",
    "\n",
    "# Compute BLEU score\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765c6ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0223c44548954cf3b5fbf0e0b58379a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\STUDY\\JAIST\\Minor_Project\\proj1\\MedEV_Evaluate\\scripts\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\phamn\\.cache\\huggingface\\hub\\datasets--nhuvo--MedEV. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e0074f064f4713a5f122bd850a4d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.en.txt:   0%|          | 0.00/48.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deaf42aee28b46de8e820425abf69ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.vi.txt:   0%|          | 0.00/61.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aa0c7a647c4797a982e9e6f57d45ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val.en.new.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3681d8c399c54b62a921f118fa30d6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val.vi.new.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9b1064934f4f6a98525b336e82dc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.en.new.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42eeaa95fb74b158cd959e2987708fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.vi.new.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec133a7d2c6a4c76b7776e083eba5646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/681794 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a655542b41d4f358a12434719e24b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab17d0caf114237bed4b1633c8786c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/17920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"nhuvo/MedEV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ebf14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d4e45817084c6993d909e0fcfd96c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2959896"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"].to_csv(\"medEV_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb44e8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'en'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m preds, refs = [], []\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m subset:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     input_text = \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# English → Vietnamese\u001b[39;00m\n\u001b[32m     22\u001b[39m     reference = sample[\u001b[33m\"\u001b[39m\u001b[33mvi\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Tokenize and translate\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'en'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "from sacrebleu import corpus_bleu\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"VietAI/envit5-translation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load MedEV dataset\n",
    "dataset = load_dataset(\"nhuvo/MedEV\", split=\"test\")\n",
    "\n",
    "# Evaluate on a small subset first (e.g. 100 sentences)\n",
    "subset = dataset.select(range(100))\n",
    "preds, refs = [], []\n",
    "\n",
    "for sample in subset:\n",
    "    input_text = sample[\"en\"]  # English → Vietnamese\n",
    "    reference = sample[\"vi\"]\n",
    "\n",
    "    # Tokenize and translate\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=256, num_beams=5)\n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    preds.append(prediction)\n",
    "    refs.append(reference)\n",
    "\n",
    "# Compute BLEU\n",
    "bleu = corpus_bleu(preds, [refs])\n",
    "print(f\"BLEU Score on 100 samples: {bleu.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0e2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  en  \\\n",
      "0  Knowledge, practices in public health service ...   \n",
      "1  Describe knowledge, practices in public health...   \n",
      "2  Methodology: A cross sectional study was used ...   \n",
      "3  Results: Percentage of card's holders who knew...   \n",
      "4  Percentage of card's holders who went to the f...   \n",
      "\n",
      "                                                  vi  \n",
      "0  Thực trạng kiến thức và thực hành của người có...  \n",
      "1  Mô tả thực trạng kiến thức, thực hành của ngườ...  \n",
      "2  Phương pháp: Thiết kế nghiên mô tả cắt ngang đ...  \n",
      "3  Kết quả: Tỷ lệ người biết được khám chữa bệnh ...  \n",
      "4  Tỷ lệ người có thẻ BHYT thực hành khám chữa bệ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"medEV_test.csv\")   # your CSV file\n",
    "texts = df[\"text\"].tolist()\n",
    "\n",
    "# Split into English and Vietnamese halves\n",
    "midpoint = len(texts) // 2\n",
    "english = texts[:midpoint]\n",
    "vietnamese = texts[midpoint:]\n",
    "\n",
    "# Pair them up\n",
    "paired_data = list(zip(english, vietnamese))\n",
    "\n",
    "# Convert to DataFrame\n",
    "aligned_df = pd.DataFrame(paired_data, columns=[\"en\", \"vi\"])\n",
    "print(aligned_df.head())\n",
    "\n",
    "# Save aligned version for later use\n",
    "aligned_df.to_csv(\"medev_test_aligned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d41480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 42.56\n"
     ]
    }
   ],
   "source": [
    "from sacrebleu import corpus_bleu\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# Load aligned dataset\n",
    "aligned_df = pd.read_csv(\"medev_test_aligned.csv\")\n",
    "\n",
    "model_name = \"VietAI/envit5-translation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "preds, refs = [], []\n",
    "\n",
    "for i in range(50):  # test on first 50 pairs\n",
    "    src = aligned_df[\"en\"][i]\n",
    "    tgt = aligned_df[\"vi\"][i]\n",
    "    \n",
    "    inputs = tokenizer(src, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=256, num_beams=5)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    #print(pred)\n",
    "    #print(tgt)\n",
    "\n",
    "    preds.append(pred)\n",
    "    refs.append(tgt)\n",
    "\n",
    "bleu = corpus_bleu(preds, [refs])\n",
    "print(f\"BLEU Score: {bleu.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb57899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 17920\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"nhuvo/MedEV\", split=\"test\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b8f7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 21.38\n"
     ]
    }
   ],
   "source": [
    "from sacrebleu import corpus_bleu\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# Load aligned dataset\n",
    "aligned_df = pd.read_csv(\"medev_test_aligned.csv\")\n",
    "\n",
    "model_name = \"VietAI/envit5-translation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "preds, refs = [], []\n",
    "\n",
    "for i in range(50):  # test on first 50 pairs\n",
    "    src = aligned_df[\"vi\"][i+50]\n",
    "    tgt = aligned_df[\"en\"][i+50]\n",
    "    \n",
    "    inputs = tokenizer(src, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=256, num_beams=5)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    #print(pred)\n",
    "    #print(tgt)\n",
    "\n",
    "    preds.append(pred)\n",
    "    refs.append(tgt)\n",
    "\n",
    "bleu = corpus_bleu(preds, [refs])\n",
    "print(f\"BLEU Score: {bleu.score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0855e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8960 sentence pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Randomly sampled 50 sentences\n",
      "BLEU Score: 25.38\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import random\n",
    "from sacrebleu import corpus_bleu\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# --- Load dataset ---\n",
    "aligned_df = pd.read_csv(r\"D:\\STUDY\\JAIST\\Minor_Project\\proj1\\MedEV_Evaluate\\scripts\\medev_test_aligned.csv\")\n",
    "print(f\"Loaded {len(aligned_df)} sentence pairs.\")\n",
    "\n",
    "# --- Randomly select 50 unique indices ---\n",
    "random.seed(42)  # for reproducibility (you can remove this line to get different samples each time)\n",
    "sample_indices = random.sample(range(len(aligned_df)), 50)\n",
    "\n",
    "# --- Load model ---\n",
    "model_name = \"VietAI/envit5-translation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "preds, refs = [], []\n",
    "\n",
    "# --- Translation loop ---\n",
    "for idx in sample_indices:\n",
    "    src = aligned_df[\"vi\"][idx]   # Vietnamese → English (you can flip if needed)\n",
    "    tgt = aligned_df[\"en\"][idx]\n",
    "\n",
    "    inputs = tokenizer(src, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=256, num_beams=5)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    preds.append(pred)\n",
    "    refs.append(tgt)\n",
    "\n",
    "# --- Compute BLEU ---\n",
    "bleu = corpus_bleu(preds, [refs])\n",
    "print(f\"\\nRandomly sampled 50 sentences\")\n",
    "print(f\"BLEU Score: {bleu.score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
